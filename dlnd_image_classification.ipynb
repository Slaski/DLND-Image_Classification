{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Image Classification\n",
    "In this project, you'll classify images from the [CIFAR-10 dataset](https://www.cs.toronto.edu/~kriz/cifar.html).  The dataset consists of airplanes, dogs, cats, and other objects. You'll preprocess the images, then train a convolutional neural network on all the samples. The images need to be normalized and the labels need to be one-hot encoded.  You'll get to apply what you learned and build a convolutional, max pooling, dropout, and fully connected layers.  At the end, you'll get to see your neural network's predictions on the sample images.\n",
    "## Get the Data\n",
    "Run the following cell to download the [CIFAR-10 dataset for python](https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CIFAR-10 Dataset: 171MB [15:16, 186KB/s]                                                                               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All files found!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile, isdir\n",
    "from tqdm import tqdm\n",
    "import problem_unittests as tests\n",
    "import tarfile\n",
    "\n",
    "cifar10_dataset_folder_path = 'cifar-10-batches-py'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile('cifar-10-python.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='CIFAR-10 Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz',\n",
    "            'cifar-10-python.tar.gz',\n",
    "            pbar.hook)\n",
    "\n",
    "if not isdir(cifar10_dataset_folder_path):\n",
    "    with tarfile.open('cifar-10-python.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()\n",
    "\n",
    "\n",
    "tests.test_folder_path(cifar10_dataset_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "The dataset is broken into batches to prevent your machine from running out of memory.  The CIFAR-10 dataset consists of 5 batches, named `data_batch_1`, `data_batch_2`, etc.. Each batch contains the labels and images that are one of the following:\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Understanding a dataset is part of making predictions on the data.  Play around with the code cell below by changing the `batch_id` and `sample_id`. The `batch_id` is the id for a batch (1-5). The `sample_id` is the id for a image and label pair in the batch.\n",
    "\n",
    "Ask yourself \"What are all possible labels?\", \"What is the range of values for the image data?\", \"Are the labels in order or random?\".  Answers to questions like these will help you preprocess the data and end up with better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Stats of batch 3:\n",
      "Samples: 10000\n",
      "Label Counts: {0: 994, 1: 1042, 2: 965, 3: 997, 4: 990, 5: 1029, 6: 978, 7: 1015, 8: 961, 9: 1029}\n",
      "First 20 Labels: [8, 5, 0, 6, 9, 2, 8, 3, 6, 2, 7, 4, 6, 9, 0, 0, 7, 3, 7, 2]\n",
      "\n",
      "Example of Image 100:\n",
      "Image - Min Value: 4 Max Value: 255\n",
      "Image - Shape: (32, 32, 3)\n",
      "Label - Label Id: 8 Name: ship\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAH0CAYAAADVH+85AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x24c758b1710>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 250,
       "width": 253
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import numpy as np\n",
    "\n",
    "# Explore the dataset\n",
    "batch_id = 3\n",
    "sample_id = 100\n",
    "helper.display_stats(cifar10_dataset_folder_path, batch_id, sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implement Preprocess Functions\n",
    "### Normalize\n",
    "In the cell below, implement the `normalize` function to take in image data, `x`, and return it as a normalized Numpy array. The values should be in the range of 0 to 1, inclusive.  The return object should be the same shape as `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def normalize(x):\n",
    "    \"\"\"\n",
    "    Normalize a list of sample image data in the range of 0 to 1\n",
    "    : x: List of image data.  The image shape is (32, 32, 3)\n",
    "    : return: Numpy array of normalize data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    a, b = 0.0, 1.0\n",
    "    xmin, xmax = 0, 255\n",
    "    \n",
    "    return a + ((x-xmin) * (b-a))/(xmax-xmin)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_normalize(normalize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-hot encode\n",
    "Just like the previous code cell, you'll be implementing a function for preprocessing.  This time, you'll implement the `one_hot_encode` function. The input, `x`, are a list of labels.  Implement the function to return the list of labels as One-Hot encoded Numpy array.  The possible values for labels are 0 to 9. The one-hot encoding function should return the same encoding for each value between each call to `one_hot_encode`.  Make sure to save the map of encodings outside the function.\n",
    "\n",
    "Hint: Don't reinvent the wheel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def one_hot_encode(x):\n",
    "    \"\"\"\n",
    "    One hot encode a list of sample labels. Return a one-hot encoded vector for each label.\n",
    "    : x: List of sample Labels\n",
    "    : return: Numpy array of one-hot encoded labels\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    result = np.zeros((len(x), 10))\n",
    "    for i in range(len(x)):\n",
    "        result[i, x[i]] = 1\n",
    "        \n",
    "    return result \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_one_hot_encode(one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Randomize Data\n",
    "As you saw from exploring the data above, the order of the samples are randomized.  It doesn't hurt to randomize it again, but you don't need to for this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess all the data and save it\n",
    "Running the code cell below will preprocess all the CIFAR-10 data and save it to file. The code below also uses 10% of the training data for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "# Preprocess Training, Validation, and Testing Data\n",
    "helper.preprocess_and_save_data(cifar10_dataset_folder_path, normalize, one_hot_encode)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Point\n",
    "This is your first checkpoint.  If you ever decide to come back to this notebook or have to restart the notebook, you can start from here.  The preprocessed data has been saved to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "import pickle\n",
    "import problem_unittests as tests\n",
    "import helper\n",
    "\n",
    "# Load the Preprocessed Validation data\n",
    "valid_features, valid_labels = pickle.load(open('preprocess_validation.p', mode='rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the network\n",
    "For the neural network, you'll build each layer into a function.  Most of the code you've seen has been outside of functions. To test your code more thoroughly, we require that you put each layer in a function.  This allows us to give you better feedback and test for simple mistakes using our unittests before you submit your project.\n",
    "\n",
    ">**Note:** If you're finding it hard to dedicate enough time for this course each week, we've provided a small shortcut to this part of the project. In the next couple of problems, you'll have the option to use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages to build each layer, except the layers you build in the \"Convolutional and Max Pooling Layer\" section.  TF Layers is similar to Keras's and TFLearn's abstraction to layers, so it's easy to pickup.\n",
    "\n",
    ">However, if you would like to get the most out of this course, try to solve all the problems _without_ using anything from the TF Layers packages. You **can** still use classes from other packages that happen to have the same name as ones you find in TF Layers! For example, instead of using the TF Layers version of the `conv2d` class, [tf.layers.conv2d](https://www.tensorflow.org/api_docs/python/tf/layers/conv2d), you would want to use the TF Neural Network version of `conv2d`, [tf.nn.conv2d](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d). \n",
    "\n",
    "Let's begin!\n",
    "\n",
    "### Input\n",
    "The neural network needs to read the image data, one-hot encoded labels, and dropout keep probability. Implement the following functions\n",
    "* Implement `neural_net_image_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `image_shape` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"x\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_label_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder)\n",
    " * Set the shape using `n_classes` with batch size set to `None`.\n",
    " * Name the TensorFlow placeholder \"y\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "* Implement `neural_net_keep_prob_input`\n",
    " * Return a [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder) for dropout keep probability.\n",
    " * Name the TensorFlow placeholder \"keep_prob\" using the TensorFlow `name` parameter in the [TF Placeholder](https://www.tensorflow.org/api_docs/python/tf/placeholder).\n",
    "\n",
    "These names will be used at the end of the project to load your saved model.\n",
    "\n",
    "Note: `None` for shapes in TensorFlow allow for a dynamic size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Input Tests Passed.\n",
      "Label Input Tests Passed.\n",
      "Keep Prob Tests Passed.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def neural_net_image_input(image_shape):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a bach of image input\n",
    "    : image_shape: Shape of the images\n",
    "    : return: Tensor for image input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=[None, image_shape[0], image_shape[1], image_shape[2]], name='x')\n",
    "\n",
    "\n",
    "def neural_net_label_input(n_classes):\n",
    "    \"\"\"\n",
    "    Return a Tensor for a batch of label input\n",
    "    : n_classes: Number of classes\n",
    "    : return: Tensor for label input.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, shape=(None, n_classes), name='y')\n",
    "\n",
    "\n",
    "def neural_net_keep_prob_input():\n",
    "    \"\"\"\n",
    "    Return a Tensor for keep probability\n",
    "    : return: Tensor for keep probability.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    return tf.placeholder(tf.float32, name='keep_prob')\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tf.reset_default_graph()\n",
    "tests.test_nn_image_inputs(neural_net_image_input)\n",
    "tests.test_nn_label_inputs(neural_net_label_input)\n",
    "tests.test_nn_keep_prob_inputs(neural_net_keep_prob_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution and Max Pooling Layer\n",
    "Convolution layers have a lot of success with images. For this code cell, you should implement the function `conv2d_maxpool` to apply convolution then max pooling:\n",
    "* Create the weight and bias using `conv_ksize`, `conv_num_outputs` and the shape of `x_tensor`.\n",
    "* Apply a convolution to `x_tensor` using weight and `conv_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "* Add bias\n",
    "* Add a nonlinear activation to the convolution.\n",
    "* Apply Max Pooling using `pool_ksize` and `pool_strides`.\n",
    " * We recommend you use same padding, but you're welcome to use any padding.\n",
    "\n",
    "**Note:** You **can't** use [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) for **this** layer, but you can still use TensorFlow's [Neural Network](https://www.tensorflow.org/api_docs/python/tf/nn) package. You may still use the shortcut option for all the **other** layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides):\n",
    "    \"\"\"\n",
    "    Apply convolution then max pooling to x_tensor\n",
    "    :param x_tensor: TensorFlow Tensor\n",
    "    :param conv_num_outputs: Number of outputs for the convolutional layer\n",
    "    :param conv_ksize: kernal size 2-D Tuple for the convolutional layer\n",
    "    :param conv_strides: Stride 2-D Tuple for convolution\n",
    "    :param pool_ksize: kernal size 2-D Tuple for pool\n",
    "    :param pool_strides: Stride 2-D Tuple for pool\n",
    "    : return: A tensor that represents convolution and max pooling of x_tensor\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    \n",
    "    # Get the dimensions\n",
    "    input_height, input_width, input_depth = list(map(int, x_tensor.get_shape().as_list()[1:]))\n",
    "    conv_kernel_height, conv_kernel_width = conv_ksize\n",
    "    pool_kernel_height, pool_kernel_width = pool_ksize\n",
    "    \n",
    "    # Define the filter weights and the bias based on those dimensions\n",
    "    filter_weights = tf.Variable(tf.truncated_normal((conv_kernel_height, conv_kernel_width, input_depth, conv_num_outputs),\n",
    "                                                     mean=0.0,\n",
    "                                                     stddev=0.1))\n",
    "    filter_bias = tf.Variable(tf.zeros(conv_num_outputs))\n",
    "    \n",
    "    # Define the CNN\n",
    "    conv_layer = tf.nn.conv2d(x_tensor, \n",
    "                              filter=filter_weights, \n",
    "                              strides=[1, conv_strides[0], conv_strides[1], 1], \n",
    "                              padding='SAME')\n",
    "    conv_layer = tf.nn.bias_add(conv_layer, filter_bias)\n",
    "    \n",
    "    # Add a nonlinear activation\n",
    "    conv_layer = tf.nn.relu(conv_layer)\n",
    "    \n",
    "    # Add a pooling layer\n",
    "    conv_layer = tf.nn.max_pool(conv_layer,\n",
    "                                ksize=[1, pool_kernel_height, pool_kernel_width, 1],\n",
    "                                strides=[1, pool_strides[0], pool_strides[1], 1],\n",
    "                                padding='SAME')\n",
    "    \n",
    "    return conv_layer \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_con_pool(conv2d_maxpool)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten Layer\n",
    "Implement the `flatten` function to change the dimension of `x_tensor` from a 4-D tensor to a 2-D tensor.  The output should be the shape (*Batch Size*, *Flattened Image Size*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def flatten(x_tensor):\n",
    "    \"\"\"\n",
    "    Flatten x_tensor to (Batch Size, Flattened Image Size)\n",
    "    : x_tensor: A tensor of size (Batch Size, ...), where ... are the image dimensions.\n",
    "    : return: A tensor of size (Batch Size, Flattened Image Size).\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    height, width, depth = x_tensor.get_shape().as_list()[1:]\n",
    "    flatten_size = int(height * width * depth)\n",
    "    return tf.reshape(x_tensor, [-1, flatten_size])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_flatten(flatten)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully-Connected Layer\n",
    "Implement the `fully_conn` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def fully_conn(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a fully connected layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function    \n",
    "    weights = tf.Variable(tf.truncated_normal([int(x_tensor.get_shape().as_list()[1]), num_outputs],\n",
    "                                              mean=0.0,\n",
    "                                              stddev=0.1))\n",
    "    bias = tf.Variable(tf.truncated_normal([num_outputs],\n",
    "                      mean=0.0,\n",
    "                      stddev=0.1))\n",
    "    \n",
    "    layer = tf.matmul(x_tensor, weights) + bias\n",
    "    layer = tf.nn.relu(layer)\n",
    "    \n",
    "    return layer\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_fully_conn(fully_conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Layer\n",
    "Implement the `output` function to apply a fully connected layer to `x_tensor` with the shape (*Batch Size*, *num_outputs*). Shortcut option: you can use classes from the [TensorFlow Layers](https://www.tensorflow.org/api_docs/python/tf/layers) or [TensorFlow Layers (contrib)](https://www.tensorflow.org/api_guides/python/contrib.layers) packages for this layer. For more of a challenge, only use other TensorFlow packages.\n",
    "\n",
    "**Note:** Activation, softmax, or cross entropy should **not** be applied to this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def output(x_tensor, num_outputs):\n",
    "    \"\"\"\n",
    "    Apply a output layer to x_tensor using weight and bias\n",
    "    : x_tensor: A 2-D tensor where the first dimension is batch size.\n",
    "    : num_outputs: The number of output that the new tensor should be.\n",
    "    : return: A 2-D tensor where the second dimension is num_outputs.\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    weights = tf.Variable(tf.truncated_normal([int(x_tensor.get_shape().as_list()[1]), num_outputs],\n",
    "                                              mean=0.0,\n",
    "                                              stddev=0.1))\n",
    "    bias = tf.Variable(tf.truncated_normal([num_outputs],\n",
    "                      mean=0.0,\n",
    "                      stddev=0.1))\n",
    "    \n",
    "    layer = tf.matmul(x_tensor, weights) + bias\n",
    "    \n",
    "    return layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_output(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Convolutional Model\n",
    "Implement the function `conv_net` to create a convolutional neural network model. The function takes in a batch of images, `x`, and outputs logits.  Use the layers you created above to create this model:\n",
    "\n",
    "* Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "* Apply a Flatten Layer\n",
    "* Apply 1, 2, or 3 Fully Connected Layers\n",
    "* Apply an Output Layer\n",
    "* Return the output\n",
    "* Apply [TensorFlow's Dropout](https://www.tensorflow.org/api_docs/python/tf/nn/dropout) to one or more layers in the model using `keep_prob`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network Built!\n"
     ]
    }
   ],
   "source": [
    "def conv_net(x, keep_prob):\n",
    "    \"\"\"\n",
    "    Create a convolutional neural network model\n",
    "    : x: Placeholder tensor that holds image data.\n",
    "    : keep_prob: Placeholder tensor that hold dropout keep probability.\n",
    "    : return: Tensor that represents logits\n",
    "    \"\"\"\n",
    "    # TODO: Apply 1, 2, or 3 Convolution and Max Pool layers\n",
    "    #    Play around with different number of outputs, kernel size and stride\n",
    "    # Function Definition from Above:\n",
    "    #    conv2d_maxpool(x_tensor, conv_num_outputs, conv_ksize, conv_strides, pool_ksize, pool_strides)\n",
    "    conv_layer = conv2d_maxpool(x, \n",
    "                                conv_num_outputs=16, \n",
    "                                conv_ksize=(5,5), \n",
    "                                conv_strides=(1,1), \n",
    "                                pool_ksize=(2,2), \n",
    "                                pool_strides=(2,2))\n",
    "    \n",
    "    conv_layer = conv2d_maxpool(conv_layer, \n",
    "                                conv_num_outputs=32, \n",
    "                                conv_ksize=(5,5), \n",
    "                                conv_strides=(1,1), \n",
    "                                pool_ksize=(2,2), \n",
    "                                pool_strides=(2,2))\n",
    "    \n",
    "    conv_layer = conv2d_maxpool(conv_layer, \n",
    "                                conv_num_outputs=64, \n",
    "                                conv_ksize=(5,5), \n",
    "                                conv_strides=(1,1), \n",
    "                                pool_ksize=(2,2), \n",
    "                                pool_strides=(2,2))\n",
    "\n",
    "    # TODO: Apply a Flatten Layer\n",
    "    # Function Definition from Above:\n",
    "    #   flatten(x_tensor)\n",
    "    flat_layer = flatten(conv_layer)\n",
    "\n",
    "    # TODO: Apply 1, 2, or 3 Fully Connected Layers\n",
    "    #    Play around with different number of outputs\n",
    "    # Function Definition from Above:\n",
    "    #   fully_conn(x_tensor, num_outputs)\n",
    "    fc_layer = fully_conn(flat_layer, 500)\n",
    "    fc_layer = tf.nn.dropout(fc_layer, keep_prob)\n",
    "    \n",
    "    fc_layer = fully_conn(fc_layer, 250)\n",
    "    fc_layer = tf.nn.dropout(fc_layer, keep_prob)\n",
    "    \n",
    "    # TODO: Apply an Output Layer\n",
    "    #    Set this to the number of classes\n",
    "    # Function Definition from Above:\n",
    "    #   output(x_tensor, num_outputs)\n",
    "    out_layer = output(fc_layer, 10)\n",
    "    \n",
    "    # TODO: return output\n",
    "    return out_layer\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "\n",
    "##############################\n",
    "## Build the Neural Network ##\n",
    "##############################\n",
    "\n",
    "# Remove previous weights, bias, inputs, etc..\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# Inputs\n",
    "x = neural_net_image_input((32, 32, 3))\n",
    "y = neural_net_label_input(10)\n",
    "keep_prob = neural_net_keep_prob_input()\n",
    "\n",
    "# Model\n",
    "logits = conv_net(x, keep_prob)\n",
    "\n",
    "# Name logits Tensor, so that is can be loaded from disk after training\n",
    "logits = tf.identity(logits, name='logits')\n",
    "\n",
    "# Loss and Optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "\n",
    "tests.test_conv_net(conv_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "### Single Optimization\n",
    "Implement the function `train_neural_network` to do a single optimization.  The optimization should use `optimizer` to optimize in `session` with a `feed_dict` of the following:\n",
    "* `x` for image input\n",
    "* `y` for labels\n",
    "* `keep_prob` for keep probability for dropout\n",
    "\n",
    "This function will be called for each batch, so `tf.global_variables_initializer()` has already been called.\n",
    "\n",
    "Note: Nothing needs to be returned. This function is only optimizing the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tests Passed\n"
     ]
    }
   ],
   "source": [
    "def train_neural_network(session, optimizer, keep_probability, feature_batch, label_batch):\n",
    "    \"\"\"\n",
    "    Optimize the session on a batch of images and labels\n",
    "    : session: Current TensorFlow session\n",
    "    : optimizer: TensorFlow optimizer function\n",
    "    : keep_probability: keep probability\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    session.run(optimizer, feed_dict={\n",
    "        x: feature_batch,\n",
    "        y: label_batch,\n",
    "        keep_prob: keep_probability\n",
    "    })\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "tests.test_train_nn(train_neural_network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Stats\n",
    "Implement the function `print_stats` to print loss and validation accuracy.  Use the global variables `valid_features` and `valid_labels` to calculate validation accuracy.  Use a keep probability of `1.0` to calculate the loss and validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_stats(session, feature_batch, label_batch, cost, accuracy):\n",
    "    \"\"\"\n",
    "    Print information about loss and validation accuracy\n",
    "    : session: Current TensorFlow session\n",
    "    : feature_batch: Batch of Numpy image data\n",
    "    : label_batch: Batch of Numpy label data\n",
    "    : cost: TensorFlow cost function\n",
    "    : accuracy: TensorFlow accuracy function\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    loss = sess.run(cost, feed_dict={\n",
    "        x: feature_batch,\n",
    "        y: label_batch,\n",
    "        keep_prob: 1.\n",
    "    })\n",
    "    \n",
    "    valid_acc = sess.run(accuracy, feed_dict={\n",
    "        x: feature_batch,\n",
    "        y: label_batch,\n",
    "        keep_prob: 1.\n",
    "    })\n",
    "    \n",
    "    print('Loss: {} Validation Accuracy: {}'.format(loss, valid_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters\n",
    "Tune the following parameters:\n",
    "* Set `epochs` to the number of iterations until the network stops learning or start overfitting\n",
    "* Set `batch_size` to the highest number that your machine has memory for.  Most people set them to common sizes of memory:\n",
    " * 64\n",
    " * 128\n",
    " * 256\n",
    " * ...\n",
    "* Set `keep_probability` to the probability of keeping a node using dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Tune Parameters\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "keep_probability = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train on a Single CIFAR-10 Batch\n",
    "Instead of training the neural network on all the CIFAR-10 batches of data, let's use a single batch. This should save time while you iterate on the model to get a better accuracy.  Once the final validation accuracy is 50% or greater, run the model on all the data in the next section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the Training on a Single Batch...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.4111499786376953 Validation Accuracy: 0.05000000074505806\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 2.4111499786376953 Validation Accuracy: 0.05000000074505806\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 2.4111499786376953 Validation Accuracy: 0.05000000074505806\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 2.4111499786376953 Validation Accuracy: 0.05000000074505806\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 2.3611502647399902 Validation Accuracy: 0.10000000149011612\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 2.4111499786376953 Validation Accuracy: 0.05000000074505806\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 2.4111499786376953 Validation Accuracy: 0.05000000074505806\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 2.4111499786376953 Validation Accuracy: 0.05000000074505806\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 2.4111499786376953 Validation Accuracy: 0.05000000074505806\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 2.4111499786376953 Validation Accuracy: 0.05000000074505806\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 2.4111499786376953 Validation Accuracy: 0.05000000074505806\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 2.4111499786376953 Validation Accuracy: 0.05000000074505806\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 2.4111499786376953 Validation Accuracy: 0.05000000074505806\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 2.4111499786376953 Validation Accuracy: 0.05000000074505806\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 2.4111499786376953 Validation Accuracy: 0.05000000074505806\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 2.4111499786376953 Validation Accuracy: 0.05000000074505806\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 2.361150026321411 Validation Accuracy: 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "print('Checking the Training on a Single Batch...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        batch_i = 1\n",
    "        for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "            train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "        print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "        print_stats(sess, batch_features, batch_labels, cost, accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fully Train the Model\n",
    "Now that you got a good accuracy with a single CIFAR-10 batch, try it with all five batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "Epoch  1, CIFAR-10 Batch 1:  Loss: 2.2787389755249023 Validation Accuracy: 0.125\n",
      "Epoch  1, CIFAR-10 Batch 2:  Loss: 2.186800479888916 Validation Accuracy: 0.25\n",
      "Epoch  1, CIFAR-10 Batch 3:  Loss: 2.135967254638672 Validation Accuracy: 0.30000001192092896\n",
      "Epoch  1, CIFAR-10 Batch 4:  Loss: 2.1575489044189453 Validation Accuracy: 0.2750000059604645\n",
      "Epoch  1, CIFAR-10 Batch 5:  Loss: 2.115110397338867 Validation Accuracy: 0.2750000059604645\n",
      "Epoch  2, CIFAR-10 Batch 1:  Loss: 2.028867721557617 Validation Accuracy: 0.42500001192092896\n",
      "Epoch  2, CIFAR-10 Batch 2:  Loss: 2.0121824741363525 Validation Accuracy: 0.4749999940395355\n",
      "Epoch  2, CIFAR-10 Batch 3:  Loss: 1.9600529670715332 Validation Accuracy: 0.5\n",
      "Epoch  2, CIFAR-10 Batch 4:  Loss: 2.085658550262451 Validation Accuracy: 0.3500000238418579\n",
      "Epoch  2, CIFAR-10 Batch 5:  Loss: 2.004488945007324 Validation Accuracy: 0.4750000238418579\n",
      "Epoch  3, CIFAR-10 Batch 1:  Loss: 2.0748634338378906 Validation Accuracy: 0.40000003576278687\n",
      "Epoch  3, CIFAR-10 Batch 2:  Loss: 1.9748693704605103 Validation Accuracy: 0.5\n",
      "Epoch  3, CIFAR-10 Batch 3:  Loss: 1.9229722023010254 Validation Accuracy: 0.550000011920929\n",
      "Epoch  3, CIFAR-10 Batch 4:  Loss: 1.9246187210083008 Validation Accuracy: 0.550000011920929\n",
      "Epoch  3, CIFAR-10 Batch 5:  Loss: 1.9441953897476196 Validation Accuracy: 0.5\n",
      "Epoch  4, CIFAR-10 Batch 1:  Loss: 1.9335168600082397 Validation Accuracy: 0.5249999761581421\n",
      "Epoch  4, CIFAR-10 Batch 2:  Loss: 1.9288229942321777 Validation Accuracy: 0.5249999761581421\n",
      "Epoch  4, CIFAR-10 Batch 3:  Loss: 1.8225793838500977 Validation Accuracy: 0.6750000715255737\n",
      "Epoch  4, CIFAR-10 Batch 4:  Loss: 1.9578559398651123 Validation Accuracy: 0.5\n",
      "Epoch  4, CIFAR-10 Batch 5:  Loss: 1.9030909538269043 Validation Accuracy: 0.550000011920929\n",
      "Epoch  5, CIFAR-10 Batch 1:  Loss: 1.966586947441101 Validation Accuracy: 0.4749999940395355\n",
      "Epoch  5, CIFAR-10 Batch 2:  Loss: 1.9176628589630127 Validation Accuracy: 0.550000011920929\n",
      "Epoch  5, CIFAR-10 Batch 3:  Loss: 1.7952598333358765 Validation Accuracy: 0.675000011920929\n",
      "Epoch  5, CIFAR-10 Batch 4:  Loss: 1.8393442630767822 Validation Accuracy: 0.625\n",
      "Epoch  5, CIFAR-10 Batch 5:  Loss: 1.8322093486785889 Validation Accuracy: 0.6499999761581421\n",
      "Epoch  6, CIFAR-10 Batch 1:  Loss: 1.925042986869812 Validation Accuracy: 0.5250000357627869\n",
      "Epoch  6, CIFAR-10 Batch 2:  Loss: 1.7978700399398804 Validation Accuracy: 0.675000011920929\n",
      "Epoch  6, CIFAR-10 Batch 3:  Loss: 1.7033272981643677 Validation Accuracy: 0.75\n",
      "Epoch  6, CIFAR-10 Batch 4:  Loss: 1.8568828105926514 Validation Accuracy: 0.625\n",
      "Epoch  6, CIFAR-10 Batch 5:  Loss: 1.8478196859359741 Validation Accuracy: 0.625\n",
      "Epoch  7, CIFAR-10 Batch 1:  Loss: 1.8994364738464355 Validation Accuracy: 0.550000011920929\n",
      "Epoch  7, CIFAR-10 Batch 2:  Loss: 1.8636293411254883 Validation Accuracy: 0.6000000238418579\n",
      "Epoch  7, CIFAR-10 Batch 3:  Loss: 1.730438470840454 Validation Accuracy: 0.7000000476837158\n",
      "Epoch  7, CIFAR-10 Batch 4:  Loss: 1.8632314205169678 Validation Accuracy: 0.6000000238418579\n",
      "Epoch  7, CIFAR-10 Batch 5:  Loss: 1.7481739521026611 Validation Accuracy: 0.7250000238418579\n",
      "Epoch  8, CIFAR-10 Batch 1:  Loss: 1.9291901588439941 Validation Accuracy: 0.5250000357627869\n",
      "Epoch  8, CIFAR-10 Batch 2:  Loss: 1.930374264717102 Validation Accuracy: 0.5249999761581421\n",
      "Epoch  8, CIFAR-10 Batch 3:  Loss: 1.7099807262420654 Validation Accuracy: 0.7250000238418579\n",
      "Epoch  8, CIFAR-10 Batch 4:  Loss: 1.8122117519378662 Validation Accuracy: 0.6500000357627869\n",
      "Epoch  8, CIFAR-10 Batch 5:  Loss: 1.6983661651611328 Validation Accuracy: 0.75\n",
      "Epoch  9, CIFAR-10 Batch 1:  Loss: 1.9240602254867554 Validation Accuracy: 0.550000011920929\n",
      "Epoch  9, CIFAR-10 Batch 2:  Loss: 1.8297407627105713 Validation Accuracy: 0.625\n",
      "Epoch  9, CIFAR-10 Batch 3:  Loss: 1.7394886016845703 Validation Accuracy: 0.7000000476837158\n",
      "Epoch  9, CIFAR-10 Batch 4:  Loss: 1.7664302587509155 Validation Accuracy: 0.7000000476837158\n",
      "Epoch  9, CIFAR-10 Batch 5:  Loss: 1.7676523923873901 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 10, CIFAR-10 Batch 1:  Loss: 1.878115177154541 Validation Accuracy: 0.574999988079071\n",
      "Epoch 10, CIFAR-10 Batch 2:  Loss: 1.8619370460510254 Validation Accuracy: 0.5750000476837158\n",
      "Epoch 10, CIFAR-10 Batch 3:  Loss: 1.707924485206604 Validation Accuracy: 0.75\n",
      "Epoch 10, CIFAR-10 Batch 4:  Loss: 1.746654748916626 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 10, CIFAR-10 Batch 5:  Loss: 1.7539399862289429 Validation Accuracy: 0.699999988079071\n",
      "Epoch 11, CIFAR-10 Batch 1:  Loss: 1.820587158203125 Validation Accuracy: 0.6500000357627869\n",
      "Epoch 11, CIFAR-10 Batch 2:  Loss: 1.8039450645446777 Validation Accuracy: 0.6749999523162842\n",
      "Epoch 11, CIFAR-10 Batch 3:  Loss: 1.5808730125427246 Validation Accuracy: 0.875\n",
      "Epoch 11, CIFAR-10 Batch 4:  Loss: 1.750746488571167 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 11, CIFAR-10 Batch 5:  Loss: 1.692476749420166 Validation Accuracy: 0.7750000357627869\n",
      "Epoch 12, CIFAR-10 Batch 1:  Loss: 1.8596608638763428 Validation Accuracy: 0.6000000238418579\n",
      "Epoch 12, CIFAR-10 Batch 2:  Loss: 1.7902793884277344 Validation Accuracy: 0.675000011920929\n",
      "Epoch 12, CIFAR-10 Batch 3:  Loss: 1.6264326572418213 Validation Accuracy: 0.8500000238418579\n",
      "Epoch 12, CIFAR-10 Batch 4:  Loss: 1.6793402433395386 Validation Accuracy: 0.800000011920929\n",
      "Epoch 12, CIFAR-10 Batch 5:  Loss: 1.706458330154419 Validation Accuracy: 0.75\n",
      "Epoch 13, CIFAR-10 Batch 1:  Loss: 1.8485922813415527 Validation Accuracy: 0.6000000238418579\n",
      "Epoch 13, CIFAR-10 Batch 2:  Loss: 1.7751109600067139 Validation Accuracy: 0.699999988079071\n",
      "Epoch 13, CIFAR-10 Batch 3:  Loss: 1.6741061210632324 Validation Accuracy: 0.7750000357627869\n",
      "Epoch 13, CIFAR-10 Batch 4:  Loss: 1.7587881088256836 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 13, CIFAR-10 Batch 5:  Loss: 1.6753041744232178 Validation Accuracy: 0.7749999761581421\n",
      "Epoch 14, CIFAR-10 Batch 1:  Loss: 1.832136869430542 Validation Accuracy: 0.625\n",
      "Epoch 14, CIFAR-10 Batch 2:  Loss: 1.7972939014434814 Validation Accuracy: 0.6749999523162842\n",
      "Epoch 14, CIFAR-10 Batch 3:  Loss: 1.5705233812332153 Validation Accuracy: 0.9000000357627869\n",
      "Epoch 14, CIFAR-10 Batch 4:  Loss: 1.7373368740081787 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 14, CIFAR-10 Batch 5:  Loss: 1.7330464124679565 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 15, CIFAR-10 Batch 1:  Loss: 1.8551805019378662 Validation Accuracy: 0.6000000238418579\n",
      "Epoch 15, CIFAR-10 Batch 2:  Loss: 1.8025416135787964 Validation Accuracy: 0.6500000357627869\n",
      "Epoch 15, CIFAR-10 Batch 3:  Loss: 1.568333387374878 Validation Accuracy: 0.9000000357627869\n",
      "Epoch 15, CIFAR-10 Batch 4:  Loss: 1.753580093383789 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 15, CIFAR-10 Batch 5:  Loss: 1.6743322610855103 Validation Accuracy: 0.7749999761581421\n",
      "Epoch 16, CIFAR-10 Batch 1:  Loss: 1.8337830305099487 Validation Accuracy: 0.6250000596046448\n",
      "Epoch 16, CIFAR-10 Batch 2:  Loss: 1.7947813272476196 Validation Accuracy: 0.6500000357627869\n",
      "Epoch 16, CIFAR-10 Batch 3:  Loss: 1.6407334804534912 Validation Accuracy: 0.8250000476837158\n",
      "Epoch 16, CIFAR-10 Batch 4:  Loss: 1.7044874429702759 Validation Accuracy: 0.7750000357627869\n",
      "Epoch 16, CIFAR-10 Batch 5:  Loss: 1.7398030757904053 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 17, CIFAR-10 Batch 1:  Loss: 1.7898292541503906 Validation Accuracy: 0.675000011920929\n",
      "Epoch 17, CIFAR-10 Batch 2:  Loss: 1.7927558422088623 Validation Accuracy: 0.675000011920929\n",
      "Epoch 17, CIFAR-10 Batch 3:  Loss: 1.5659996271133423 Validation Accuracy: 0.9000000357627869\n",
      "Epoch 17, CIFAR-10 Batch 4:  Loss: 1.673596739768982 Validation Accuracy: 0.7999999523162842\n",
      "Epoch 17, CIFAR-10 Batch 5:  Loss: 1.6754852533340454 Validation Accuracy: 0.7749999761581421\n",
      "Epoch 18, CIFAR-10 Batch 1:  Loss: 1.7828986644744873 Validation Accuracy: 0.6750000715255737\n",
      "Epoch 18, CIFAR-10 Batch 2:  Loss: 1.8113930225372314 Validation Accuracy: 0.6500000357627869\n",
      "Epoch 18, CIFAR-10 Batch 3:  Loss: 1.6642924547195435 Validation Accuracy: 0.7750000357627869\n",
      "Epoch 18, CIFAR-10 Batch 4:  Loss: 1.790490984916687 Validation Accuracy: 0.675000011920929\n",
      "Epoch 18, CIFAR-10 Batch 5:  Loss: 1.6877669095993042 Validation Accuracy: 0.7750000953674316\n",
      "Epoch 19, CIFAR-10 Batch 1:  Loss: 1.7837163209915161 Validation Accuracy: 0.6750000715255737\n",
      "Epoch 19, CIFAR-10 Batch 2:  Loss: 1.7909353971481323 Validation Accuracy: 0.6749999523162842\n",
      "Epoch 19, CIFAR-10 Batch 3:  Loss: 1.5701875686645508 Validation Accuracy: 0.9000000357627869\n",
      "Epoch 19, CIFAR-10 Batch 4:  Loss: 1.6159591674804688 Validation Accuracy: 0.8500000238418579\n",
      "Epoch 19, CIFAR-10 Batch 5:  Loss: 1.6613662242889404 Validation Accuracy: 0.8000000715255737\n",
      "Epoch 20, CIFAR-10 Batch 1:  Loss: 1.7560888528823853 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 20, CIFAR-10 Batch 2:  Loss: 1.7995928525924683 Validation Accuracy: 0.6499999761581421\n",
      "Epoch 20, CIFAR-10 Batch 3:  Loss: 1.5904426574707031 Validation Accuracy: 0.875\n",
      "Epoch 20, CIFAR-10 Batch 4:  Loss: 1.7013559341430664 Validation Accuracy: 0.75\n",
      "Epoch 20, CIFAR-10 Batch 5:  Loss: 1.629485845565796 Validation Accuracy: 0.8250000476837158\n",
      "Epoch 21, CIFAR-10 Batch 1:  Loss: 1.7635836601257324 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 21, CIFAR-10 Batch 2:  Loss: 1.8146804571151733 Validation Accuracy: 0.6499999761581421\n",
      "Epoch 21, CIFAR-10 Batch 3:  Loss: 1.6121110916137695 Validation Accuracy: 0.8500000238418579\n",
      "Epoch 21, CIFAR-10 Batch 4:  Loss: 1.651532530784607 Validation Accuracy: 0.800000011920929\n",
      "Epoch 21, CIFAR-10 Batch 5:  Loss: 1.760841965675354 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 22, CIFAR-10 Batch 1:  Loss: 1.7488147020339966 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 22, CIFAR-10 Batch 2:  Loss: 1.7366669178009033 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 22, CIFAR-10 Batch 3:  Loss: 1.5519282817840576 Validation Accuracy: 0.925000011920929\n",
      "Epoch 22, CIFAR-10 Batch 4:  Loss: 1.6904487609863281 Validation Accuracy: 0.7750000357627869\n",
      "Epoch 22, CIFAR-10 Batch 5:  Loss: 1.6668963432312012 Validation Accuracy: 0.800000011920929\n",
      "Epoch 23, CIFAR-10 Batch 1:  Loss: 1.7372548580169678 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 23, CIFAR-10 Batch 2:  Loss: 1.7349634170532227 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 23, CIFAR-10 Batch 3:  Loss: 1.619525671005249 Validation Accuracy: 0.8500000834465027\n",
      "Epoch 23, CIFAR-10 Batch 4:  Loss: 1.608379602432251 Validation Accuracy: 0.8500000834465027\n",
      "Epoch 23, CIFAR-10 Batch 5:  Loss: 1.7708828449249268 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 24, CIFAR-10 Batch 1:  Loss: 1.8045861721038818 Validation Accuracy: 0.6500000357627869\n",
      "Epoch 24, CIFAR-10 Batch 2:  Loss: 1.710498571395874 Validation Accuracy: 0.75\n",
      "Epoch 24, CIFAR-10 Batch 3:  Loss: 1.5603713989257812 Validation Accuracy: 0.9000000357627869\n",
      "Epoch 24, CIFAR-10 Batch 4:  Loss: 1.6912782192230225 Validation Accuracy: 0.7749999761581421\n",
      "Epoch 24, CIFAR-10 Batch 5:  Loss: 1.6597106456756592 Validation Accuracy: 0.800000011920929\n",
      "Epoch 25, CIFAR-10 Batch 1:  Loss: 1.7844061851501465 Validation Accuracy: 0.6750000715255737\n",
      "Epoch 25, CIFAR-10 Batch 2:  Loss: 1.8244881629943848 Validation Accuracy: 0.6500000357627869\n",
      "Epoch 25, CIFAR-10 Batch 3:  Loss: 1.5713140964508057 Validation Accuracy: 0.8750000596046448\n",
      "Epoch 25, CIFAR-10 Batch 4:  Loss: 1.635514736175537 Validation Accuracy: 0.8250000476837158\n",
      "Epoch 25, CIFAR-10 Batch 5:  Loss: 1.6361290216445923 Validation Accuracy: 0.8250000476837158\n",
      "Epoch 26, CIFAR-10 Batch 1:  Loss: 1.75199294090271 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 26, CIFAR-10 Batch 2:  Loss: 1.7355560064315796 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 26, CIFAR-10 Batch 3:  Loss: 1.5666745901107788 Validation Accuracy: 0.9000000357627869\n",
      "Epoch 26, CIFAR-10 Batch 4:  Loss: 1.6924749612808228 Validation Accuracy: 0.7749999761581421\n",
      "Epoch 26, CIFAR-10 Batch 5:  Loss: 1.642399787902832 Validation Accuracy: 0.8250000476837158\n",
      "Epoch 27, CIFAR-10 Batch 1:  Loss: 1.8400845527648926 Validation Accuracy: 0.6250000596046448\n",
      "Epoch 27, CIFAR-10 Batch 2:  Loss: 1.7339527606964111 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 27, CIFAR-10 Batch 3:  Loss: 1.6090800762176514 Validation Accuracy: 0.8500000238418579\n",
      "Epoch 27, CIFAR-10 Batch 4:  Loss: 1.6820275783538818 Validation Accuracy: 0.7750000357627869\n",
      "Epoch 27, CIFAR-10 Batch 5:  Loss: 1.637058138847351 Validation Accuracy: 0.8250000476837158\n",
      "Epoch 28, CIFAR-10 Batch 1:  Loss: 1.7698256969451904 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 28, CIFAR-10 Batch 2:  Loss: 1.781467318534851 Validation Accuracy: 0.6749999523162842\n",
      "Epoch 28, CIFAR-10 Batch 3:  Loss: 1.561286211013794 Validation Accuracy: 0.8999999761581421\n",
      "Epoch 28, CIFAR-10 Batch 4:  Loss: 1.628727674484253 Validation Accuracy: 0.8250000476837158\n",
      "Epoch 28, CIFAR-10 Batch 5:  Loss: 1.5863380432128906 Validation Accuracy: 0.875\n",
      "Epoch 29, CIFAR-10 Batch 1:  Loss: 1.837204933166504 Validation Accuracy: 0.625\n",
      "Epoch 29, CIFAR-10 Batch 2:  Loss: 1.8203933238983154 Validation Accuracy: 0.6499999761581421\n",
      "Epoch 29, CIFAR-10 Batch 3:  Loss: 1.6387152671813965 Validation Accuracy: 0.824999988079071\n",
      "Epoch 29, CIFAR-10 Batch 4:  Loss: 1.641302466392517 Validation Accuracy: 0.824999988079071\n",
      "Epoch 29, CIFAR-10 Batch 5:  Loss: 1.6861644983291626 Validation Accuracy: 0.7750000357627869\n",
      "Epoch 30, CIFAR-10 Batch 1:  Loss: 1.7609304189682007 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 30, CIFAR-10 Batch 2:  Loss: 1.7801668643951416 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 30, CIFAR-10 Batch 3:  Loss: 1.536158800125122 Validation Accuracy: 0.925000011920929\n",
      "Epoch 30, CIFAR-10 Batch 4:  Loss: 1.6864783763885498 Validation Accuracy: 0.7749999761581421\n",
      "Epoch 30, CIFAR-10 Batch 5:  Loss: 1.6523916721343994 Validation Accuracy: 0.8000000715255737\n",
      "Epoch 31, CIFAR-10 Batch 1:  Loss: 1.7815306186676025 Validation Accuracy: 0.6750000715255737\n",
      "Epoch 31, CIFAR-10 Batch 2:  Loss: 1.8705041408538818 Validation Accuracy: 0.6000000238418579\n",
      "Epoch 31, CIFAR-10 Batch 3:  Loss: 1.6112079620361328 Validation Accuracy: 0.8500000238418579\n",
      "Epoch 31, CIFAR-10 Batch 4:  Loss: 1.7351268529891968 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 31, CIFAR-10 Batch 5:  Loss: 1.7155230045318604 Validation Accuracy: 0.75\n",
      "Epoch 32, CIFAR-10 Batch 1:  Loss: 1.809053897857666 Validation Accuracy: 0.6499999761581421\n",
      "Epoch 32, CIFAR-10 Batch 2:  Loss: 1.806959629058838 Validation Accuracy: 0.6500000357627869\n",
      "Epoch 32, CIFAR-10 Batch 3:  Loss: 1.6363856792449951 Validation Accuracy: 0.824999988079071\n",
      "Epoch 32, CIFAR-10 Batch 4:  Loss: 1.674100637435913 Validation Accuracy: 0.7749999761581421\n",
      "Epoch 32, CIFAR-10 Batch 5:  Loss: 1.7343251705169678 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 33, CIFAR-10 Batch 1:  Loss: 1.7359048128128052 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 33, CIFAR-10 Batch 2:  Loss: 1.8360109329223633 Validation Accuracy: 0.625\n",
      "Epoch 33, CIFAR-10 Batch 3:  Loss: 1.560326099395752 Validation Accuracy: 0.9000000357627869\n",
      "Epoch 33, CIFAR-10 Batch 4:  Loss: 1.7118680477142334 Validation Accuracy: 0.75\n",
      "Epoch 33, CIFAR-10 Batch 5:  Loss: 1.7914328575134277 Validation Accuracy: 0.675000011920929\n",
      "Epoch 34, CIFAR-10 Batch 1:  Loss: 1.8360744714736938 Validation Accuracy: 0.625\n",
      "Epoch 34, CIFAR-10 Batch 2:  Loss: 1.811161994934082 Validation Accuracy: 0.6499999761581421\n",
      "Epoch 34, CIFAR-10 Batch 3:  Loss: 1.682394027709961 Validation Accuracy: 0.7750000357627869\n",
      "Epoch 34, CIFAR-10 Batch 4:  Loss: 1.6337108612060547 Validation Accuracy: 0.8250000476837158\n",
      "Epoch 34, CIFAR-10 Batch 5:  Loss: 1.878832459449768 Validation Accuracy: 0.574999988079071\n",
      "Epoch 35, CIFAR-10 Batch 1:  Loss: 1.7611329555511475 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 35, CIFAR-10 Batch 2:  Loss: 1.76571524143219 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 35, CIFAR-10 Batch 3:  Loss: 1.6860930919647217 Validation Accuracy: 0.7750000357627869\n",
      "Epoch 35, CIFAR-10 Batch 4:  Loss: 1.6859346628189087 Validation Accuracy: 0.7749999761581421\n",
      "Epoch 35, CIFAR-10 Batch 5:  Loss: 1.7331657409667969 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 36, CIFAR-10 Batch 1:  Loss: 1.73611319065094 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 36, CIFAR-10 Batch 2:  Loss: 1.8908964395523071 Validation Accuracy: 0.5750000476837158\n",
      "Epoch 36, CIFAR-10 Batch 3:  Loss: 1.752563714981079 Validation Accuracy: 0.699999988079071\n",
      "Epoch 36, CIFAR-10 Batch 4:  Loss: 1.6861658096313477 Validation Accuracy: 0.7750000357627869\n",
      "Epoch 36, CIFAR-10 Batch 5:  Loss: 1.7604044675827026 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 37, CIFAR-10 Batch 1:  Loss: 1.751316785812378 Validation Accuracy: 0.699999988079071\n",
      "Epoch 37, CIFAR-10 Batch 2:  Loss: 1.8261773586273193 Validation Accuracy: 0.625\n",
      "Epoch 37, CIFAR-10 Batch 3:  Loss: 1.5966241359710693 Validation Accuracy: 0.875\n",
      "Epoch 37, CIFAR-10 Batch 4:  Loss: 1.7922499179840088 Validation Accuracy: 0.6750000715255737\n",
      "Epoch 37, CIFAR-10 Batch 5:  Loss: 1.6612701416015625 Validation Accuracy: 0.800000011920929\n",
      "Epoch 38, CIFAR-10 Batch 1:  Loss: 1.9257493019104004 Validation Accuracy: 0.5250000357627869\n",
      "Epoch 38, CIFAR-10 Batch 2:  Loss: 1.8610661029815674 Validation Accuracy: 0.6000000238418579\n",
      "Epoch 38, CIFAR-10 Batch 3:  Loss: 1.7349121570587158 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 38, CIFAR-10 Batch 4:  Loss: 1.6624650955200195 Validation Accuracy: 0.8000000715255737\n",
      "Epoch 38, CIFAR-10 Batch 5:  Loss: 1.6650536060333252 Validation Accuracy: 0.7999999523162842\n",
      "Epoch 39, CIFAR-10 Batch 1:  Loss: 1.7966943979263306 Validation Accuracy: 0.675000011920929\n",
      "Epoch 39, CIFAR-10 Batch 2:  Loss: 1.8095556497573853 Validation Accuracy: 0.6499999761581421\n",
      "Epoch 39, CIFAR-10 Batch 3:  Loss: 1.7111512422561646 Validation Accuracy: 0.75\n",
      "Epoch 39, CIFAR-10 Batch 4:  Loss: 1.8116414546966553 Validation Accuracy: 0.6499999761581421\n",
      "Epoch 39, CIFAR-10 Batch 5:  Loss: 1.7361793518066406 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 40, CIFAR-10 Batch 1:  Loss: 1.8360919952392578 Validation Accuracy: 0.625\n",
      "Epoch 40, CIFAR-10 Batch 2:  Loss: 1.7355501651763916 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 40, CIFAR-10 Batch 3:  Loss: 1.5861365795135498 Validation Accuracy: 0.875\n",
      "Epoch 40, CIFAR-10 Batch 4:  Loss: 1.686150074005127 Validation Accuracy: 0.7749999761581421\n",
      "Epoch 40, CIFAR-10 Batch 5:  Loss: 1.7518916130065918 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 41, CIFAR-10 Batch 1:  Loss: 1.8845655918121338 Validation Accuracy: 0.574999988079071\n",
      "Epoch 41, CIFAR-10 Batch 2:  Loss: 1.8369954824447632 Validation Accuracy: 0.625\n",
      "Epoch 41, CIFAR-10 Batch 3:  Loss: 1.7014634609222412 Validation Accuracy: 0.7500000596046448\n",
      "Epoch 41, CIFAR-10 Batch 4:  Loss: 1.805474042892456 Validation Accuracy: 0.6499999761581421\n",
      "Epoch 41, CIFAR-10 Batch 5:  Loss: 1.751267433166504 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 42, CIFAR-10 Batch 1:  Loss: 1.7608892917633057 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 42, CIFAR-10 Batch 2:  Loss: 1.8611358404159546 Validation Accuracy: 0.6000000238418579\n",
      "Epoch 42, CIFAR-10 Batch 3:  Loss: 1.7610303163528442 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 42, CIFAR-10 Batch 4:  Loss: 1.735626459121704 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 42, CIFAR-10 Batch 5:  Loss: 1.8111895322799683 Validation Accuracy: 0.6500000357627869\n",
      "Epoch 43, CIFAR-10 Batch 1:  Loss: 1.7611511945724487 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 43, CIFAR-10 Batch 2:  Loss: 1.8605868816375732 Validation Accuracy: 0.6000000238418579\n",
      "Epoch 43, CIFAR-10 Batch 3:  Loss: 1.7353019714355469 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 43, CIFAR-10 Batch 4:  Loss: 1.8109885454177856 Validation Accuracy: 0.6499999761581421\n",
      "Epoch 43, CIFAR-10 Batch 5:  Loss: 1.7361503839492798 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 44, CIFAR-10 Batch 1:  Loss: 1.8105862140655518 Validation Accuracy: 0.6500000357627869\n",
      "Epoch 44, CIFAR-10 Batch 2:  Loss: 1.8365843296051025 Validation Accuracy: 0.625\n",
      "Epoch 44, CIFAR-10 Batch 3:  Loss: 1.733959674835205 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 44, CIFAR-10 Batch 4:  Loss: 1.7477853298187256 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 44, CIFAR-10 Batch 5:  Loss: 1.736149549484253 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 45, CIFAR-10 Batch 1:  Loss: 1.8361501693725586 Validation Accuracy: 0.6250000596046448\n",
      "Epoch 45, CIFAR-10 Batch 2:  Loss: 1.9617807865142822 Validation Accuracy: 0.5\n",
      "Epoch 45, CIFAR-10 Batch 3:  Loss: 1.6111505031585693 Validation Accuracy: 0.8500000834465027\n",
      "Epoch 45, CIFAR-10 Batch 4:  Loss: 1.738276720046997 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 45, CIFAR-10 Batch 5:  Loss: 1.6861519813537598 Validation Accuracy: 0.7750000953674316\n",
      "Epoch 46, CIFAR-10 Batch 1:  Loss: 1.985843300819397 Validation Accuracy: 0.4750000238418579\n",
      "Epoch 46, CIFAR-10 Batch 2:  Loss: 1.8111501932144165 Validation Accuracy: 0.6499999761581421\n",
      "Epoch 46, CIFAR-10 Batch 3:  Loss: 1.8361501693725586 Validation Accuracy: 0.625\n",
      "Epoch 46, CIFAR-10 Batch 4:  Loss: 1.7855098247528076 Validation Accuracy: 0.675000011920929\n",
      "Epoch 46, CIFAR-10 Batch 5:  Loss: 1.8611700534820557 Validation Accuracy: 0.5999999642372131\n",
      "Epoch 47, CIFAR-10 Batch 1:  Loss: 1.935753583908081 Validation Accuracy: 0.5250000357627869\n",
      "Epoch 47, CIFAR-10 Batch 2:  Loss: 1.8840265274047852 Validation Accuracy: 0.5750000476837158\n",
      "Epoch 47, CIFAR-10 Batch 3:  Loss: 1.7859302759170532 Validation Accuracy: 0.6750000715255737\n",
      "Epoch 47, CIFAR-10 Batch 4:  Loss: 1.8867599964141846 Validation Accuracy: 0.5750000476837158\n",
      "Epoch 47, CIFAR-10 Batch 5:  Loss: 1.7861502170562744 Validation Accuracy: 0.6749999523162842\n",
      "Epoch 48, CIFAR-10 Batch 1:  Loss: 1.811052680015564 Validation Accuracy: 0.6500000357627869\n",
      "Epoch 48, CIFAR-10 Batch 2:  Loss: 1.8354811668395996 Validation Accuracy: 0.625\n",
      "Epoch 48, CIFAR-10 Batch 3:  Loss: 1.7361502647399902 Validation Accuracy: 0.7250000238418579\n",
      "Epoch 48, CIFAR-10 Batch 4:  Loss: 1.7594249248504639 Validation Accuracy: 0.699999988079071\n",
      "Epoch 48, CIFAR-10 Batch 5:  Loss: 1.8361501693725586 Validation Accuracy: 0.625\n",
      "Epoch 49, CIFAR-10 Batch 1:  Loss: 1.886017084121704 Validation Accuracy: 0.5750000476837158\n",
      "Epoch 49, CIFAR-10 Batch 2:  Loss: 1.8611500263214111 Validation Accuracy: 0.6000000238418579\n",
      "Epoch 49, CIFAR-10 Batch 3:  Loss: 1.7111375331878662 Validation Accuracy: 0.7500000596046448\n",
      "Epoch 49, CIFAR-10 Batch 4:  Loss: 1.7877552509307861 Validation Accuracy: 0.675000011920929\n",
      "Epoch 49, CIFAR-10 Batch 5:  Loss: 1.861139178276062 Validation Accuracy: 0.6000000238418579\n",
      "Epoch 50, CIFAR-10 Batch 1:  Loss: 1.9111491441726685 Validation Accuracy: 0.550000011920929\n",
      "Epoch 50, CIFAR-10 Batch 2:  Loss: 1.8062149286270142 Validation Accuracy: 0.6500000357627869\n",
      "Epoch 50, CIFAR-10 Batch 3:  Loss: 1.796255111694336 Validation Accuracy: 0.675000011920929\n",
      "Epoch 50, CIFAR-10 Batch 4:  Loss: 1.7613495588302612 Validation Accuracy: 0.7000000476837158\n",
      "Epoch 50, CIFAR-10 Batch 5:  Loss: 1.8361486196517944 Validation Accuracy: 0.625\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "save_model_path = './image_classification'\n",
    "\n",
    "print('Training...')\n",
    "with tf.Session() as sess:\n",
    "    # Initializing the variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Training cycle\n",
    "    for epoch in range(epochs):\n",
    "        # Loop over all batches\n",
    "        n_batches = 5\n",
    "        for batch_i in range(1, n_batches + 1):\n",
    "            for batch_features, batch_labels in helper.load_preprocess_training_batch(batch_i, batch_size):\n",
    "                train_neural_network(sess, optimizer, keep_probability, batch_features, batch_labels)\n",
    "            print('Epoch {:>2}, CIFAR-10 Batch {}:  '.format(epoch + 1, batch_i), end='')\n",
    "            print_stats(sess, batch_features, batch_labels, cost, accuracy)\n",
    "            \n",
    "    # Save Model\n",
    "    saver = tf.train.Saver()\n",
    "    save_path = saver.save(sess, save_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checkpoint\n",
    "The model has been saved to disk.\n",
    "## Test Model\n",
    "Test your model against the test dataset.  This will be your final accuracy. You should have an accuracy greater than 50%. If you don't, keep tweaking the model architecture and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.5435126582278481\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAJ/CAYAAACUb342AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x21ed1c14828>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 319,
       "width": 355
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import helper\n",
    "import random\n",
    "\n",
    "# Set batch size if not already set\n",
    "try:\n",
    "    if batch_size:\n",
    "        pass\n",
    "except NameError:\n",
    "    batch_size = 64\n",
    "\n",
    "save_model_path = './image_classification'\n",
    "n_samples = 4\n",
    "top_n_predictions = 3\n",
    "\n",
    "def test_model():\n",
    "    \"\"\"\n",
    "    Test the saved model against the test dataset\n",
    "    \"\"\"\n",
    "\n",
    "    test_features, test_labels = pickle.load(open('preprocess_training.p', mode='rb'))\n",
    "    loaded_graph = tf.Graph()\n",
    "\n",
    "    with tf.Session(graph=loaded_graph) as sess:\n",
    "        # Load model\n",
    "        loader = tf.train.import_meta_graph(save_model_path + '.meta')\n",
    "        loader.restore(sess, save_model_path)\n",
    "\n",
    "        # Get Tensors from loaded model\n",
    "        loaded_x = loaded_graph.get_tensor_by_name('x:0')\n",
    "        loaded_y = loaded_graph.get_tensor_by_name('y:0')\n",
    "        loaded_keep_prob = loaded_graph.get_tensor_by_name('keep_prob:0')\n",
    "        loaded_logits = loaded_graph.get_tensor_by_name('logits:0')\n",
    "        loaded_acc = loaded_graph.get_tensor_by_name('accuracy:0')\n",
    "        \n",
    "        # Get accuracy in batches for memory limitations\n",
    "        test_batch_acc_total = 0\n",
    "        test_batch_count = 0\n",
    "        \n",
    "        for train_feature_batch, train_label_batch in helper.batch_features_labels(test_features, test_labels, batch_size):\n",
    "            test_batch_acc_total += sess.run(\n",
    "                loaded_acc,\n",
    "                feed_dict={loaded_x: train_feature_batch, loaded_y: train_label_batch, loaded_keep_prob: 1.0})\n",
    "            test_batch_count += 1\n",
    "\n",
    "        print('Testing Accuracy: {}\\n'.format(test_batch_acc_total/test_batch_count))\n",
    "\n",
    "        # Print Random Samples\n",
    "        random_test_features, random_test_labels = tuple(zip(*random.sample(list(zip(test_features, test_labels)), n_samples)))\n",
    "        random_test_predictions = sess.run(\n",
    "            tf.nn.top_k(tf.nn.softmax(loaded_logits), top_n_predictions),\n",
    "            feed_dict={loaded_x: random_test_features, loaded_y: random_test_labels, loaded_keep_prob: 1.0})\n",
    "        helper.display_image_predictions(random_test_features, random_test_labels, random_test_predictions)\n",
    "\n",
    "\n",
    "test_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why 50-70% Accuracy?\n",
    "You might be wondering why you can't get an accuracy any higher. First things first, 50% isn't bad for a simple CNN.  Pure guessing would get you 10% accuracy. However, you might notice people are getting scores [well above 70%](http://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html#43494641522d3130).  That's because we haven't taught you all there is to know about neural networks. We still need to cover a few more techniques.\n",
    "## Submitting This Project\n",
    "When submitting this project, make sure to run all the cells before saving the notebook.  Save the notebook file as \"dlnd_image_classification.ipynb\" and save it as a HTML file under \"File\" -> \"Download as\".  Include the \"helper.py\" and \"problem_unittests.py\" files in your submission."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
